# ----------------------------
# LLM Configuration
# ----------------------------
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3

# Optional OpenAI / Azure (mocked for free)
OPENAI_API_KEY=
OPENAI_MODEL=
AZURE_OPENAI_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_DEPLOYMENT=
AZURE_OPENAI_VERSION=

# ----------------------------
# Data / Vector Store
# ----------------------------
DATA_DIR=data/raw
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
FAISS_INDEX_PATH=data/processed/faiss_index

# Pinecone (optional, demo or future integration)
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=
PINECONE_INDEX_NAME=
USE_PINECONE=False

# ----------------------------
# Server / FastAPI
# ----------------------------
HOST=127.0.0.1
PORT=8000

# ----------------------------
# Misc / Reliability
# ----------------------------
RETRY_COUNT=3
TIMEOUT_SECONDS=20
CIRCUIT_BREAKER_THRESHOLD=3
CIRCUIT_BREAKER_RECOVERY=30
